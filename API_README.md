# ScraperLLM API

A FastAPI-based web service that provides web scraping and semantic query expansion capabilities.

## ğŸš€ Features

- **Web Scraping**: Extract content from web pages using CSS selectors
- **Query Expansion**: Generate semantically related search queries using a trained AI model
- **RESTful API**: Well-documented endpoints with OpenAPI/Swagger UI
- **CORS Support**: Pre-configured for Webflow integration
- **Docker Support**: Easy containerization for deployment
- **Railway Ready**: Optimized for deployment on Railway.app

## ğŸ—ï¸ Project Structure

```
scraperllm/
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py              # FastAPI app initialization
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py        # Application configuration
â”‚   â”‚   â””â”€â”€ logging.py       # Logging configuration
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ status.py        # Health check and system status
â”‚   â”‚   â”œâ”€â”€ scrape.py        # Web scraping endpoints
â”‚   â”‚   â””â”€â”€ query.py         # Query expansion endpoints
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ semantic_expander.py  # AI model integration
â”œâ”€â”€ models/                  # Trained model files (not in version control)
â”œâ”€â”€ tests/                   # Test files
â”œâ”€â”€ .env.example             # Example environment variables
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ Dockerfile               # Docker configuration
â”œâ”€â”€ railway.toml             # Railway.app deployment config
â””â”€â”€ README.md               # This file
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+
- pip (Python package manager)
- Docker (for containerized deployment)
- A trained model file in the `models/` directory

### Local Development

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/ScraperLLM.git
   cd ScraperLLM
   ```

2. Create and activate a virtual environment:
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: .\venv\Scripts\activate
   ```

3. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

4. Create a `.env` file from the example:
   ```bash
   cp .env.example .env
   ```
   Edit the `.env` file with your configuration.

5. Run the development server:
   ```bash
   uvicorn api.main:app --reload
   ```

6. Access the API documentation at `http://localhost:8000/docs`

## ğŸ› ï¸ API Endpoints

### Status
- `GET /api/status` - Check API status and system information
- `GET /api/health` - Simple health check endpoint

### Scraping
- `POST /api/scrape` - Scrape a website with CSS selectors

### Query Expansion
- `POST /api/query/expand` - Generate semantically related search queries
- `GET /api/query/status` - Check the status of the semantic expansion model

## ğŸ³ Docker Deployment

1. Build the Docker image:
   ```bash
   docker build -t scraperllm-api .
   ```

2. Run the container:
   ```bash
   docker run -d --name scraperllm-api -p 8000:8000 --env-file .env scraperllm-api
   ```

## ğŸš‚ Railway Deployment

1. Install the Railway CLI:
   ```bash
   npm i -g @railway/cli
   ```

2. Login to Railway:
   ```bash
   railway login
   ```

3. Link your project:
   ```bash
   railway link
   ```

4. Set environment variables:
   ```bash
   railway env push .env
   ```

5. Deploy:
   ```bash
   railway up
   ```

## ğŸ”§ Configuration

Environment variables can be set in the `.env` file or in your deployment platform's environment settings:

- `MODEL_PATH`: Path to the trained model directory (default: `models/query_expander`)
- `LOG_LEVEL`: Logging level (default: `INFO`)
- `CORS_ORIGINS`: Comma-separated list of allowed origins (default: `http://localhost:3000,https://*.webflow.io,https://livewebscraper.com`)
- `RATE_LIMIT`: Maximum requests per minute (default: `60`)

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘ Acknowledgments

- [FastAPI](https://fastapi.tiangolo.com/) - The web framework used
- [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/) - For HTML parsing
- [Hugging Face](https://huggingface.co/) - For the transformer models
- [Railway](https://railway.app/) - For deployment hosting
